#!/usr/bin/env python3
"""
Script de validaÃ§Ã£o e testes especÃ­ficos para o Tech Challenge
Valida cada requisito individualmente e gera relatÃ³rio detalhado
"""

import pandas as pd
import os
import json
import logging
from datetime import datetime, date
from pathlib import Path
import unittest
from typing import Dict, List, Any

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TechChallengeValidator:
    """Classe para validar todos os requisitos do Tech Challenge"""
    
    def __init__(self, pipeline_dir: str = "./pipeline_test"):
        """
        Inicializa o validador
        
        Args:
            pipeline_dir: DiretÃ³rio com os resultados do pipeline
        """
        self.pipeline_dir = Path(pipeline_dir)
        self.raw_data_dir = self.pipeline_dir / "raw-data"
        self.refined_data_dir = self.pipeline_dir / "refined-data"
        self.logs_dir = self.pipeline_dir / "logs"
        
        self.validation_results = {}
    
    def validate_requirement_1(self) -> Dict[str, Any]:
        """
        Valida Requisito 1: Scrap de dados do site da B3
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisito 1: Scrap de dados da B3")
        
        result = {
            "requirement": "Req 1 - Scrap de dados do site da B3",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar se existe script de scrap
            script_path = Path("scripts/b3_scraper.py")
            if script_path.exists():
                result["details"].append("âœ“ Script de scrap implementado")
                
                # Verificar se o script contÃ©m as funcionalidades necessÃ¡rias
                with open(script_path, 'r') as f:
                    script_content = f.read()
                
                required_features = [
                    ("requests", "Biblioteca requests para HTTP"),
                    ("BeautifulSoup", "Parser HTML BeautifulSoup"),
                    ("parquet", "Suporte a formato Parquet"),
                    ("boto3", "IntegraÃ§Ã£o com AWS S3")
                ]
                
                for feature, description in required_features:
                    if feature in script_content:
                        result["details"].append(f"âœ“ {description} presente")
                    else:
                        result["issues"].append(f"âš  {description} nÃ£o encontrado")
                
            else:
                result["status"] = "FAIL"
                result["issues"].append("âŒ Script de scrap nÃ£o encontrado")
            
            # Verificar se dados foram coletados
            raw_files = list(self.raw_data_dir.glob("**/*.parquet"))
            if raw_files:
                result["details"].append(f"âœ“ {len(raw_files)} arquivo(s) de dados brutos encontrado(s)")
                
                # Verificar estrutura dos dados
                df = pd.read_parquet(raw_files[0])
                expected_columns = ['codigo', 'acao', 'tipo', 'qtde_teorica', 'participacao_pct']
                
                for col in expected_columns:
                    if col in df.columns:
                        result["details"].append(f"âœ“ Coluna '{col}' presente nos dados")
                    else:
                        result["issues"].append(f"âš  Coluna '{col}' ausente nos dados")
                        
            else:
                result["issues"].append("âš  Nenhum arquivo de dados brutos encontrado")
                
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def validate_requirement_2(self) -> Dict[str, Any]:
        """
        Valida Requisito 2: Dados brutos no S3 em formato Parquet com partiÃ§Ã£o diÃ¡ria
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisito 2: S3 Parquet com partiÃ§Ã£o diÃ¡ria")
        
        result = {
            "requirement": "Req 2 - S3 Parquet com partiÃ§Ã£o diÃ¡ria",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar estrutura de particionamento
            expected_structure = ["year=", "month=", "day="]
            
            for root, dirs, files in os.walk(self.raw_data_dir):
                path_parts = Path(root).parts
                
                # Verificar se contÃ©m particionamento por data
                has_year = any("year=" in part for part in path_parts)
                has_month = any("month=" in part for part in path_parts)
                has_day = any("day=" in part for part in path_parts)
                
                if has_year and has_month and has_day:
                    result["details"].append("âœ“ Particionamento por year/month/day implementado")
                    break
            else:
                result["issues"].append("âš  Particionamento por data nÃ£o encontrado")
            
            # Verificar arquivos Parquet
            parquet_files = list(self.raw_data_dir.glob("**/*.parquet"))
            if parquet_files:
                result["details"].append(f"âœ“ {len(parquet_files)} arquivo(s) Parquet encontrado(s)")
                
                # Verificar se Ã© possÃ­vel ler os arquivos
                for file in parquet_files:
                    try:
                        df = pd.read_parquet(file)
                        result["details"].append(f"âœ“ Arquivo {file.name} legÃ­vel ({len(df)} registros)")
                    except Exception as e:
                        result["issues"].append(f"âŒ Erro ao ler {file.name}: {str(e)}")
                        
            else:
                result["status"] = "FAIL"
                result["issues"].append("âŒ Nenhum arquivo Parquet encontrado")
                
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def validate_requirement_3_4(self) -> Dict[str, Any]:
        """
        Valida Requisitos 3 e 4: Lambda trigger e linguagem
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisitos 3 e 4: Lambda trigger")
        
        result = {
            "requirement": "Req 3-4 - Lambda trigger para Glue",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar se existe funÃ§Ã£o Lambda
            lambda_path = Path("lambda/trigger_glue_job.py")
            if lambda_path.exists():
                result["details"].append("âœ“ FunÃ§Ã£o Lambda implementada")
                
                with open(lambda_path, 'r') as f:
                    lambda_content = f.read()
                
                # Verificar funcionalidades da Lambda
                required_features = [
                    ("boto3", "Cliente AWS SDK"),
                    ("glue", "IntegraÃ§Ã£o com AWS Glue"),
                    ("start_job_run", "InicializaÃ§Ã£o de job Glue"),
                    ("Records", "Processamento de eventos S3")
                ]
                
                for feature, description in required_features:
                    if feature in lambda_content:
                        result["details"].append(f"âœ“ {description} implementado")
                    else:
                        result["issues"].append(f"âš  {description} nÃ£o encontrado")
                
                # Verificar se Ã© Python (Requisito 4)
                if "python" in lambda_content.lower() or lambda_path.suffix == ".py":
                    result["details"].append("âœ“ Linguagem Python utilizada")
                
            else:
                result["status"] = "FAIL"
                result["issues"].append("âŒ FunÃ§Ã£o Lambda nÃ£o encontrada")
            
            # Verificar simulaÃ§Ã£o de evento S3
            event_file = self.logs_dir / "s3_event_simulation.json"
            if event_file.exists():
                result["details"].append("âœ“ Evento S3 simulado")
                
                with open(event_file, 'r') as f:
                    event_data = json.load(f)
                
                if "Records" in event_data and event_data["Records"]:
                    result["details"].append("âœ“ Estrutura de evento S3 vÃ¡lida")
                else:
                    result["issues"].append("âš  Estrutura de evento S3 invÃ¡lida")
                    
            else:
                result["issues"].append("âš  SimulaÃ§Ã£o de evento S3 nÃ£o encontrada")
                
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def validate_requirement_5(self) -> Dict[str, Any]:
        """
        Valida Requisito 5: Job Glue visual com transformaÃ§Ãµes
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisito 5: Job Glue com transformaÃ§Ãµes")
        
        result = {
            "requirement": "Req 5 - Job Glue visual com transformaÃ§Ãµes",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar configuraÃ§Ã£o do job Glue
            glue_config = Path("glue-jobs/glue_job_config.json")
            if glue_config.exists():
                result["details"].append("âœ“ ConfiguraÃ§Ã£o do job Glue encontrada")
                
                with open(glue_config, 'r') as f:
                    config = json.load(f)
                
                # Verificar modo visual
                if config.get("jobMode") == "VISUAL":
                    result["details"].append("âœ“ Job configurado em modo visual")
                else:
                    result["issues"].append("âš  Job nÃ£o estÃ¡ em modo visual")
                
            else:
                result["issues"].append("âš  ConfiguraÃ§Ã£o do job Glue nÃ£o encontrada")
            
            # Verificar dados refinados para validar transformaÃ§Ãµes
            refined_files = list(self.refined_data_dir.glob("**/*.parquet"))
            if refined_files:
                result["details"].append(f"âœ“ {len(refined_files)} arquivo(s) refinado(s) encontrado(s)")
                
                # Carregar dados para verificar transformaÃ§Ãµes
                dfs = [pd.read_parquet(f) for f in refined_files]
                combined_df = pd.concat(dfs, ignore_index=True)
                
                # Verificar TransformaÃ§Ã£o A: Agrupamento/SumarizaÃ§Ã£o
                if 'total_quantidade_teorica' in combined_df.columns:
                    result["details"].append("âœ“ TransformaÃ§Ã£o A: SumarizaÃ§Ã£o implementada")
                else:
                    result["issues"].append("âŒ TransformaÃ§Ã£o A: SumarizaÃ§Ã£o nÃ£o encontrada")
                
                # Verificar TransformaÃ§Ã£o B: RenomeaÃ§Ã£o de colunas
                renamed_columns = ['quantidade_teorica_acoes', 'percentual_participacao_ibov']
                found_renamed = [col for col in renamed_columns if col in combined_df.columns]
                
                if len(found_renamed) >= 2:
                    result["details"].append(f"âœ“ TransformaÃ§Ã£o B: {len(found_renamed)} colunas renomeadas")
                else:
                    result["issues"].append(f"âŒ TransformaÃ§Ã£o B: Apenas {len(found_renamed)} colunas renomeadas (necessÃ¡rio 2)")
                
                # Verificar TransformaÃ§Ã£o C: CÃ¡lculo com data
                date_columns = [col for col in combined_df.columns if 'dia' in col.lower() or 'date' in col.lower()]
                if date_columns:
                    result["details"].append("âœ“ TransformaÃ§Ã£o C: CÃ¡lculo com data implementado")
                else:
                    result["issues"].append("âŒ TransformaÃ§Ã£o C: CÃ¡lculo com data nÃ£o encontrado")
                
            else:
                result["status"] = "FAIL"
                result["issues"].append("âŒ Nenhum arquivo refinado encontrado")
                
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def validate_requirement_6(self) -> Dict[str, Any]:
        """
        Valida Requisito 6: Dados refinados com particionamento
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisito 6: Dados refinados particionados")
        
        result = {
            "requirement": "Req 6 - Dados refinados particionados",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar estrutura de particionamento refinado
            refined_structure_found = False
            
            for root, dirs, files in os.walk(self.refined_data_dir):
                path_parts = Path(root).parts
                
                # Verificar particionamento por data e aÃ§Ã£o
                has_year = any("year=" in part for part in path_parts)
                has_month = any("month=" in part for part in path_parts)
                has_day = any("day=" in part for part in path_parts)
                has_action = any("tipo=" in part for part in path_parts)
                
                if has_year and has_month and has_day and has_action:
                    refined_structure_found = True
                    result["details"].append("âœ“ Particionamento por data e tipo de aÃ§Ã£o implementado")
                    break
            
            if not refined_structure_found:
                result["issues"].append("âŒ Particionamento duplo (data + aÃ§Ã£o) nÃ£o encontrado")
            
            # Verificar pasta refined
            if "refined" in str(self.refined_data_dir):
                result["details"].append("âœ“ Pasta 'refined' utilizada")
            else:
                result["issues"].append("âš  Pasta 'refined' nÃ£o identificada")
            
            # Verificar formato Parquet nos dados refinados
            refined_parquet = list(self.refined_data_dir.glob("**/*.parquet"))
            if refined_parquet:
                result["details"].append(f"âœ“ {len(refined_parquet)} arquivo(s) Parquet refinado(s)")
            else:
                result["status"] = "FAIL"
                result["issues"].append("âŒ Nenhum arquivo Parquet refinado encontrado")
                
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def validate_requirement_7(self) -> Dict[str, Any]:
        """
        Valida Requisito 7: CatalogaÃ§Ã£o automÃ¡tica no Glue Catalog
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisito 7: Glue Data Catalog")
        
        result = {
            "requirement": "Req 7 - Glue Data Catalog",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar simulaÃ§Ã£o do catÃ¡logo
            catalog_file = self.logs_dir / "glue_catalog_simulation.json"
            if catalog_file.exists():
                result["details"].append("âœ“ ConfiguraÃ§Ã£o do Data Catalog simulada")
                
                with open(catalog_file, 'r') as f:
                    catalog_data = json.load(f)
                
                # Verificar database default
                if catalog_data.get("database") == "default" or "default" in str(catalog_data.get("database", "")):
                    result["details"].append("âœ“ Database 'default' configurado")
                else:
                    result["issues"].append("âš  Database 'default' nÃ£o configurado")
                
                # Verificar tabela
                if "table" in catalog_data:
                    result["details"].append(f"âœ“ Tabela '{catalog_data.get('table')}' configurada")
                else:
                    result["issues"].append("âš  ConfiguraÃ§Ã£o de tabela nÃ£o encontrada")
                
                # Verificar schema
                if "schema" in catalog_data:
                    result["details"].append("âœ“ Schema da tabela definido")
                else:
                    result["issues"].append("âš  Schema da tabela nÃ£o definido")
                
            else:
                result["issues"].append("âš  ConfiguraÃ§Ã£o do Data Catalog nÃ£o encontrada")
            
            # Verificar configuraÃ§Ã£o no job Glue
            glue_config = Path("glue-jobs/glue_job_config.json")
            if glue_config.exists():
                with open(glue_config, 'r') as f:
                    config = json.load(f)
                
                # Procurar por configuraÃ§Ã£o de catalogaÃ§Ã£o
                dag_str = json.dumps(config.get("dag", {}))
                if "enableUpdateCatalog" in dag_str or "UPDATE_IN_DATABASE" in dag_str:
                    result["details"].append("âœ“ CatalogaÃ§Ã£o automÃ¡tica configurada no job Glue")
                else:
                    result["issues"].append("âš  CatalogaÃ§Ã£o automÃ¡tica nÃ£o configurada")
                    
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def validate_requirement_8(self) -> Dict[str, Any]:
        """
        Valida Requisito 8: Dados disponÃ­veis no Athena
        
        Returns:
            Resultado da validaÃ§Ã£o
        """
        logger.info("ğŸ” Validando Requisito 8: Disponibilidade no Athena")
        
        result = {
            "requirement": "Req 8 - Dados disponÃ­veis no Athena",
            "status": "PASS",
            "details": [],
            "issues": []
        }
        
        try:
            # Verificar simulaÃ§Ã£o de consultas Athena
            athena_file = self.logs_dir / "athena_queries_simulation.json"
            if athena_file.exists():
                result["details"].append("âœ“ Consultas Athena simuladas")
                
                with open(athena_file, 'r') as f:
                    queries_data = json.load(f)
                
                # Verificar tipos de consulta
                query_types = list(queries_data.keys())
                result["details"].append(f"âœ“ {len(query_types)} tipo(s) de consulta testado(s)")
                
                # Verificar se hÃ¡ resultados
                for query_type, query_info in queries_data.items():
                    if "resultado" in query_info and query_info["resultado"]:
                        result["details"].append(f"âœ“ Consulta '{query_type}' retornou dados")
                    else:
                        result["issues"].append(f"âš  Consulta '{query_type}' sem resultados")
                
            else:
                result["issues"].append("âš  SimulaÃ§Ã£o de consultas Athena nÃ£o encontrada")
            
            # Verificar se dados refinados sÃ£o legÃ­veis (simulando Athena)
            refined_files = list(self.refined_data_dir.glob("**/*.parquet"))
            readable_files = 0
            
            for file in refined_files:
                try:
                    df = pd.read_parquet(file)
                    if len(df) > 0:
                        readable_files += 1
                except:
                    pass
            
            if readable_files > 0:
                result["details"].append(f"âœ“ {readable_files} arquivo(s) legÃ­vel(is) para consulta")
            else:
                result["status"] = "FAIL"
                result["issues"].append("âŒ Nenhum arquivo legÃ­vel encontrado")
                
        except Exception as e:
            result["status"] = "ERROR"
            result["issues"].append(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        return result
    
    def run_full_validation(self) -> Dict[str, Any]:
        """
        Executa validaÃ§Ã£o completa de todos os requisitos
        
        Returns:
            RelatÃ³rio completo de validaÃ§Ã£o
        """
        logger.info("ğŸ” INICIANDO VALIDAÃ‡ÃƒO COMPLETA DOS REQUISITOS")
        logger.info("=" * 60)
        
        validators = [
            self.validate_requirement_1,
            self.validate_requirement_2,
            self.validate_requirement_3_4,
            self.validate_requirement_5,
            self.validate_requirement_6,
            self.validate_requirement_7,
            self.validate_requirement_8
        ]
        
        validation_results = []
        passed_count = 0
        
        for validator in validators:
            try:
                result = validator()
                validation_results.append(result)
                
                # Log resultado
                status_emoji = "âœ…" if result["status"] == "PASS" else "âŒ" if result["status"] == "FAIL" else "âš ï¸"
                logger.info(f"{status_emoji} {result['requirement']}: {result['status']}")
                
                if result["status"] == "PASS":
                    passed_count += 1
                
                # Log detalhes
                for detail in result["details"]:
                    logger.info(f"    {detail}")
                
                # Log issues
                for issue in result["issues"]:
                    logger.warning(f"    {issue}")
                
            except Exception as e:
                logger.error(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        
        # RelatÃ³rio final
        total_requirements = len(validation_results)
        success_rate = (passed_count / total_requirements) * 100 if total_requirements > 0 else 0
        
        final_report = {
            "validation_summary": {
                "timestamp": datetime.now().isoformat(),
                "total_requirements": total_requirements,
                "passed": passed_count,
                "failed": total_requirements - passed_count,
                "success_rate": round(success_rate, 2)
            },
            "detailed_results": validation_results,
            "overall_status": "PASS" if passed_count == total_requirements else "PARTIAL" if passed_count > 0 else "FAIL"
        }
        
        # Salvar relatÃ³rio
        report_file = self.logs_dir / "validation_report.json"
        with open(report_file, 'w') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        logger.info("=" * 60)
        logger.info(f"ğŸ VALIDAÃ‡ÃƒO CONCLUÃDA: {passed_count}/{total_requirements} requisitos aprovados")
        logger.info(f"ğŸ“Š Taxa de sucesso: {success_rate:.1f}%")
        logger.info(f"ğŸ“„ RelatÃ³rio salvo em: {report_file}")
        
        return final_report

def main():
    """FunÃ§Ã£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ValidaÃ§Ã£o dos requisitos do Tech Challenge')
    parser.add_argument('--pipeline-dir', default='./pipeline_test', help='DiretÃ³rio do pipeline')
    
    args = parser.parse_args()
    
    # Executar validaÃ§Ã£o
    validator = TechChallengeValidator(pipeline_dir=args.pipeline_dir)
    report = validator.run_full_validation()
    
    # Exit code baseado no resultado
    if report["overall_status"] == "PASS":
        exit(0)
    elif report["overall_status"] == "PARTIAL":
        exit(1)
    else:
        exit(2)

if __name__ == "__main__":
    main()

