# Tech Challenge Fase 2 - Big Data Architecture

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um pipeline completo de dados para extrair, processar e analisar dados do pregÃ£o da B3 (Bovespa), utilizando serviÃ§os AWS para criar uma arquitetura escalÃ¡vel de Big Data.

## ğŸ—ï¸ Arquitetura

![Diagrama da Arquitetura](docs/diagrama_arquitetura.png)

### Componentes Principais

- **ğŸŒ Web Scraping**: Script Python para coleta de dados da B3
- **ğŸ—„ï¸ Amazon S3**: Armazenamento de dados raw e refined em formato Parquet
- **âš¡ AWS Lambda**: OrquestraÃ§Ã£o event-driven do pipeline
- **ğŸ”„ AWS Glue**: Processamento ETL visual com Apache Spark
- **ğŸ“š Glue Data Catalog**: CatalogaÃ§Ã£o automÃ¡tica de metadados
- **ğŸ” Amazon Athena**: Engine de consultas SQL serverless

## ğŸ“‹ Requisitos Atendidos

- âœ… **Req 1**: Scrap de dados do site da B3
- âœ… **Req 2**: Dados brutos no S3 em formato Parquet com partiÃ§Ã£o diÃ¡ria
- âœ… **Req 3**: Bucket S3 aciona Lambda que chama job Glue
- âœ… **Req 4**: Lambda implementada em Python
- âœ… **Req 5A**: Agrupamento numÃ©rico e sumarizaÃ§Ã£o
- âœ… **Req 5B**: RenomeaÃ§Ã£o de duas colunas
- âœ… **Req 5C**: CÃ¡lculo com campos de data
- âœ… **Req 6**: Dados refinados particionados por data e aÃ§Ã£o
- âœ… **Req 7**: CatalogaÃ§Ã£o automÃ¡tica no Glue Data Catalog
- âœ… **Req 8**: Dados disponÃ­veis no Athena

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.11+
- AWS CLI configurado
- Conta AWS com permissÃµes adequadas

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd tech-challenge-bovespa

# Instale dependÃªncias
pip install -r requirements.txt
```

### Teste Local

```bash
# Execute o pipeline completo localmente
python scripts/test_pipeline.py

# Execute validaÃ§Ã£o dos requisitos
python scripts/validation_tests.py
```

### Deploy na AWS

Siga o guia detalhado em [`docs/instrucoes_implementacao.md`](docs/instrucoes_implementacao.md)

## ğŸ“ Estrutura do Projeto

```
tech-challenge-bovespa/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ b3_scraper.py           # Script de web scraping
â”‚   â”œâ”€â”€ test_pipeline.py        # Teste completo do pipeline
â”‚   â””â”€â”€ validation_tests.py     # ValidaÃ§Ã£o de requisitos
â”œâ”€â”€ lambda/
â”‚   â””â”€â”€ trigger_glue_job.py     # FunÃ§Ã£o Lambda
â”œâ”€â”€ glue-jobs/
â”‚   â””â”€â”€ glue_job_config.json    # ConfiguraÃ§Ã£o do job Glue
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ arquitetura_aws.md      # DocumentaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ instrucoes_implementacao.md  # Guia de implementaÃ§Ã£o
â”‚   â”œâ”€â”€ relatorio_final.md      # RelatÃ³rio completo
â”‚   â”œâ”€â”€ relatorio_final.pdf     # RelatÃ³rio em PDF
â”‚   â””â”€â”€ diagrama_arquitetura.png # Diagrama visual
â”œâ”€â”€ pipeline_test/              # Resultados dos testes
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â””â”€â”€ README.md                   # Este arquivo
```

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Resultados dos Testes

- **Pipeline End-to-End**: âœ… 5/5 passos concluÃ­dos
- **ValidaÃ§Ã£o de Requisitos**: âœ… 7/7 requisitos aprovados
- **Taxa de Sucesso**: 100%

### MÃ©tricas de Performance

- **LatÃªncia de IngestÃ£o**: ~45 segundos
- **LatÃªncia de Processamento**: ~3 minutos
- **Throughput de Consulta**: 2-8 segundos
- **CompressÃ£o de Dados**: 70-80% vs CSV

## ğŸ’° Estimativa de Custos

| ServiÃ§o | Custo Mensal (USD) |
|---------|-------------------|
| S3 Storage (1GB) | $0.023 |
| Lambda (30 exec) | $0.001 |
| Glue (30 jobs Ã— 5min) | $1.10 |
| Athena (consultas) | $0.50 |
| CloudWatch | $0.10 |
| **Total** | **$1.73** |

## ğŸ“Š TransformaÃ§Ãµes Implementadas

### TransformaÃ§Ã£o A: Agrupamento
- Agrupamento por tipo de aÃ§Ã£o (ON, PN, etc.)
- Soma da quantidade teÃ³rica por grupo
- CÃ¡lculo de participaÃ§Ã£o mÃ©dia

### TransformaÃ§Ã£o B: RenomeaÃ§Ã£o
- `qtde_teorica` â†’ `quantidade_teorica_acoes`
- `participacao_pct` â†’ `percentual_participacao_ibov`

### TransformaÃ§Ã£o C: CÃ¡lculo de Data
- CÃ¡lculo de `dias_desde_coleta`
- DiferenÃ§a entre data atual e timestamp de coleta

## ğŸ” Consultas de Exemplo

```sql
-- AnÃ¡lise por tipo de aÃ§Ã£o
SELECT tipo, 
       total_acoes_por_tipo,
       total_quantidade_teorica,
       participacao_media
FROM bovespa_refined_data 
ORDER BY total_quantidade_teorica DESC;

-- EvoluÃ§Ã£o temporal
SELECT year, month, day,
       SUM(total_acoes_por_tipo) as total_acoes,
       SUM(total_quantidade_teorica) as quantidade_total
FROM bovespa_refined_data
GROUP BY year, month, day
ORDER BY year, month, day;
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.11**: Linguagem principal
- **Apache Spark 3.3**: Processamento distribuÃ­do
- **Apache Parquet**: Formato de armazenamento colunar
- **AWS S3**: Data Lake
- **AWS Lambda**: ComputaÃ§Ã£o serverless
- **AWS Glue**: ETL gerenciado
- **Amazon Athena**: Query engine serverless
- **BeautifulSoup4**: Web scraping
- **Pandas**: ManipulaÃ§Ã£o de dados
- **Boto3**: SDK AWS para Python

## ğŸ“ˆ Monitoramento

- **CloudWatch Logs**: Logs centralizados
- **CloudWatch Metrics**: MÃ©tricas customizadas
- **Alertas**: NotificaÃ§Ãµes proativas
- **Dashboard**: Visibilidade operacional

## ğŸ”’ SeguranÃ§a

- **IAM Roles**: PrincÃ­pio de menor privilÃ©gio
- **Criptografia**: TLS em trÃ¢nsito, SSE-S3 em repouso
- **Auditoria**: CloudTrail para todas as aÃ§Ãµes
- **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de integridade de dados

## ğŸš€ PrÃ³ximos Passos

### Curto Prazo
- [ ] Implementar cache Redis
- [ ] Otimizar particionamento
- [ ] Alertas inteligentes com ML

### MÃ©dio Prazo
- [ ] Adicionar outros Ã­ndices
- [ ] Streaming analytics com Kinesis
- [ ] IntegraÃ§Ã£o com QuickSight

### Longo Prazo
- [ ] Modelos de ML preditivos
- [ ] Arquitetura multi-region
- [ ] APIs REST pÃºblicas

## ğŸ“š DocumentaÃ§Ã£o

- [ğŸ“– RelatÃ³rio Final Completo](docs/relatorio_final.pdf)
- [ğŸ—ï¸ DocumentaÃ§Ã£o da Arquitetura](docs/arquitetura_aws.md)
- [âš™ï¸ Guia de ImplementaÃ§Ã£o](docs/instrucoes_implementacao.md)

## ğŸ¤ ContribuiÃ§Ã£o

Este projeto foi desenvolvido como parte do Tech Challenge Fase 2. Para sugestÃµes ou melhorias, abra uma issue ou pull request.

## ğŸ“„ LicenÃ§a

Este projeto Ã© desenvolvido para fins educacionais como parte do Tech Challenge.

---

**Desenvolvido por**: Gustavo Imbelloni  
**Data**: Junho 2025  
**VersÃ£o**: 1.0.0

